# EFT AI ì„œë²„

EFT(ê°ì •ììœ ê¸°ë²•) ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ AI ì„œë²„ì…ë‹ˆë‹¤. Llama 3 ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ ì‹¬ë¦¬ìƒë‹´ì— íŠ¹í™”ëœ AI ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# Python ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ í•„ìš”í•œ ì„¤ì • ì…ë ¥
```

### 2. ì„œë²„ ì‹¤í–‰

```bash
# ê°œë°œ ëª¨ë“œ (ìë™ ì¬ë¡œë“œ, ë””ë²„ê·¸ ë¡œê·¸)
python start.py --env dev --reload

# ìš´ì˜ ëª¨ë“œ (ì„±ëŠ¥ ìµœì í™”)
python start.py --env prod --model-preset llama3-8b-optimal

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ê°€ë²¼ìš´ ëª¨ë¸)
python start.py --model-preset llama2-7b-quick
```

### 3. API í…ŒìŠ¤íŠ¸

ì„œë²„ ì‹¤í–‰ í›„ ë‹¤ìŒ ì£¼ì†Œì—ì„œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥:
- API ë¬¸ì„œ: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc
- í—¬ìŠ¤ ì²´í¬: http://localhost:8000/health

## ğŸ“– API ì‚¬ìš©ë²•

### ê¸°ë³¸ ì±„íŒ… API

```bash
curl -X POST "http://localhost:8000/api/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ì˜¤ëŠ˜ ë„ˆë¬´ ìŠ¤íŠ¸ë ˆìŠ¤ë°›ì•„ì„œ í˜ë“¤ì–´ìš”",
    "max_tokens": 400,
    "temperature": 0.7
  }'
```

### ê°ì • ë¶„ì„ API

```bash
curl -X POST "http://localhost:8000/api/analyze/emotion" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "íšŒì‚¬ì—ì„œ ìƒì‚¬ê°€ ê³„ì† ì•¼ê·¼ì‹œì¼œì„œ ë„ˆë¬´ í™”ë‚˜ìš”"
  }'
```

### ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… (ì‹¤ì‹œê°„)

```javascript
// JavaScript ì˜ˆì‹œ
const response = await fetch('http://localhost:8000/api/chat/stream', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    message: "ë¶ˆì•ˆí•œ ë§ˆìŒì„ ë‹¬ë˜ê³  ì‹¶ì–´ìš”"
  })
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value);
  console.log('AI ì‘ë‹µ ì²­í¬:', chunk);
}
```

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```
backend/
â”œâ”€â”€ main.py              # FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
â”œâ”€â”€ start.py             # ì„œë²„ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt     # Python ì˜ì¡´ì„±
â”œâ”€â”€ .env.example         # í™˜ê²½ë³€ìˆ˜ í…œí”Œë¦¿
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py      # ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ models/
â”‚   â””â”€â”€ chat_models.py   # Pydantic ëª¨ë¸ë“¤
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ai_engine.py     # Llama 3 AI ì—”ì§„
â”‚   â”œâ”€â”€ prompt_manager.py # EFT ì „ë¬¸ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
â”‚   â””â”€â”€ emotion_analyzer.py # ê°ì • ë¶„ì„ê¸°
â””â”€â”€ utils/
    â””â”€â”€ logger.py        # ë¡œê¹… ì‹œìŠ¤í…œ
```

## âš™ï¸ ì„¤ì • ì˜µì…˜

### ëª¨ë¸ í”„ë¦¬ì…‹

- `llama2-7b-quick`: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© (6GB VRAM)
- `llama3-8b-optimal`: ê¶Œì¥ ìš´ì˜ìš© (12GB VRAM)  
- `llama3-70b-premium`: ê³ ì„±ëŠ¥ìš© (40GB+ VRAM)

### ì£¼ìš” í™˜ê²½ë³€ìˆ˜

```env
# AI ëª¨ë¸
MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct
DEVICE=auto              # cuda, cpu, auto
LOAD_IN_4BIT=true        # ë©”ëª¨ë¦¬ ì ˆì•½
MAX_MEMORY=8GiB          # GPU ë©”ëª¨ë¦¬ ì œí•œ

# ì„œë²„
HOST=0.0.0.0
PORT=8000
DEBUG=true

# ë¡œê·¸
LOG_LEVEL=INFO
LOG_FILE=./logs/eft_ai_server.log

# ë³´ì•ˆ
SECRET_KEY=your-secret-key
ALLOWED_ORIGINS=["http://localhost:3000"]
```

## ğŸ”§ ê°œë°œ ê°€ì´ë“œ

### ë¡œì»¬ ê°œë°œ

```bash
# ê°œë°œ ëª¨ë“œë¡œ ì‹¤í–‰ (ìë™ ì¬ë¡œë“œ)
python start.py --env dev --reload --log-level DEBUG

# íŠ¹ì • ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
python start.py --model-preset llama2-7b-quick --reload
```

### ì½”ë“œ êµ¬ì¡°

```python
# ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.post("/api/my-feature")
async def my_feature(request: MyRequest):
    # 1. ìš”ì²­ ê²€ì¦
    # 2. AI ì—”ì§„ í˜¸ì¶œ  
    # 3. ì‘ë‹µ í›„ì²˜ë¦¬
    # 4. ê²°ê³¼ ë°˜í™˜
    pass
```

### ë¡œê¹…

```python
from utils.logger import get_logger

logger = get_logger(__name__)

# ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë¡œê¹…
with LogContext(logger, user_id=user_id, session_id=session_id):
    logger.info("ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬ ì¤‘...")
```

## ğŸ³ Docker ë°°í¬

```dockerfile
# Dockerfile ì˜ˆì‹œ (ì¶”í›„ ì¶”ê°€)
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "start.py", "--env", "prod"]
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ì„±ëŠ¥ ë©”íŠ¸ë¦­

- `/api/stats`: ëª¨ë¸ ì„±ëŠ¥ í†µê³„
- `/health`: ì„œë²„ ìƒíƒœ ì²´í¬
- Prometheus ë©”íŠ¸ë¦­ (ì„ íƒì‚¬í•­)

### ë¡œê·¸ ë¶„ì„

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
tail -f logs/eft_ai_server.log

# êµ¬ì¡°í™”ëœ ë¡œê·¸ ê²€ìƒ‰
grep "ERROR" logs/eft_ai_server_structured.jsonl
```

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

1. **API í‚¤ ê´€ë¦¬**: `.env` íŒŒì¼ì— ë¯¼ê°í•œ ì •ë³´ ì €ì¥
2. **CORS ì„¤ì •**: í—ˆìš©ëœ ë„ë©”ì¸ë§Œ ì ‘ê·¼ ê°€ëŠ¥
3. **ì…ë ¥ ê²€ì¦**: ëª¨ë“  ì‚¬ìš©ì ì…ë ¥ ê²€ì¦
4. **ë¡œê·¸ ë§ˆìŠ¤í‚¹**: ê°œì¸ì •ë³´ ë¡œê·¸ ê¸°ë¡ ë°©ì§€

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

**Q: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨**
```bash
# CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
export MAX_MEMORY=4GiB
python start.py --model-preset llama2-7b-quick

# Hugging Face í† í° í•„ìš”
export HUGGINGFACE_TOKEN=hf_your_token
```

**Q: ì‘ë‹µ ì†ë„ ëŠë¦¼**
```bash
# GPU ì‚¬ìš© í™•ì¸
nvidia-smi

# 4bit ì–‘ìí™” í™œì„±í™”
export LOAD_IN_4BIT=true
```

**Q: ë©”ëª¨ë¦¬ ë¶€ì¡±**
```bash
# CPU ëª¨ë“œë¡œ ì‹¤í–‰
export DEVICE=cpu
python start.py
```

### ë””ë²„ê¹…

```bash
# ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰
python start.py --log-level DEBUG --reload

# Python ì¸í„°í”„ë¦¬í„°ì—ì„œ ì§ì ‘ í…ŒìŠ¤íŠ¸
python -c "
from services.ai_engine import EFTAIEngine
engine = EFTAIEngine()
print('AI ì—”ì§„ ì´ˆê¸°í™” ì„±ê³µ')
"
```

## ğŸ“š ì¶”ê°€ ìë£Œ

- [FastAPI ë¬¸ì„œ](https://fastapi.tiangolo.com/)
- [Transformers ë¬¸ì„œ](https://huggingface.co/docs/transformers)
- [Llama ëª¨ë¸ ì¹´ë“œ](https://huggingface.co/meta-llama)
- [EFT ê¸°ë²• ê°€ì´ë“œ](../docs/eft-guide.md)

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. ì´ìŠˆ ìƒì„± ë˜ëŠ” ê¸°ì¡´ ì´ìŠˆ í™•ì¸
2. ê¸°ëŠ¥ ë¸Œëœì¹˜ ìƒì„±: `git checkout -b feature/my-feature`
3. ë³€ê²½ì‚¬í•­ ì»¤ë°‹: `git commit -m "Add my feature"`
4. ë¸Œëœì¹˜ í‘¸ì‹œ: `git push origin feature/my-feature`
5. Pull Request ìƒì„±

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ì œê³µë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ LICENSE íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.