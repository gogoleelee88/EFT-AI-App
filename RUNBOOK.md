# EFT AI ìƒë‹´ ì„œë¹„ìŠ¤ ìš´ì˜ ë§¤ë‰´ì–¼ (RUNBOOK)

## ğŸš€ **ë¶€íŒ… ìˆœì„œ (í•„ìˆ˜ ì¤€ìˆ˜)**

### **1ë‹¨ê³„: vLLM ì—”ì§„ ì‹¤í–‰ (WSL2)**
```bash
# WSL2 Ubuntuì—ì„œ ì‹¤í–‰
source ~/vllm-venv/bin/activate

# í„°ë¯¸ë„ A - Engine A (Llama-3-8B)
python -m vllm.entrypoints.openai.api_server \
  --model meta-llama/Meta-Llama-3-8B-Instruct \
  --dtype auto --max-model-len 4096 --gpu-memory-utilization 0.9 \
  --port 8001

# í„°ë¯¸ë„ B - Engine B (Qwen2.5-7B)  
python -m vllm.entrypoints.openai.api_server \
  --model Qwen/Qwen2.5-7B-Instruct \
  --dtype auto --max-model-len 4096 --gpu-memory-utilization 0.9 \
  --port 8002
```

### **2ë‹¨ê³„: ì—…ìŠ¤íŠ¸ë¦¼ ìƒíƒœ í™•ì¸**
```bash
curl http://127.0.0.1:8000/health/upstreams
```
**âœ… ì„±ê³µ ì¡°ê±´:** ë‘ ì—”ì§„ ëª¨ë‘ `"status": "healthy"` ë°˜í™˜

### **3ë‹¨ê³„: ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰ (Windows)**
```bash
cd "C:\Users\lco20\Desktop\EFT-AI-App\backend"
set PYTHONUTF8=1 && python main.py
```

### **4ë‹¨ê³„: API ë¬¸ì„œ í™•ì¸**
- ë¸Œë¼ìš°ì €: http://127.0.0.1:8000/docs

### **5ë‹¨ê³„: í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰**
```bash
cd "C:\Users\lco20\Desktop\EFT-AI-App\frontend"
npm run dev
```
- ë¸Œë¼ìš°ì €: http://localhost:5173

---

## ğŸ”§ **í™˜ê²½ë³€ìˆ˜ ì„¤ì •í‘œ**

### **ê°œë°œ í™˜ê²½ (.env)**
```bash
# í•„ìˆ˜
HUGGINGFACE_TOKEN=hf_YOUR_TOKEN_HERE
DEBUG=true
HOST=0.0.0.0
PORT=8000

# A/B í…ŒìŠ¤íŠ¸
AB_TEST_STRATEGY=round_robin
FREE_ENGINES_WEIGHTS=engine_a:1,engine_b:1

# ì¶”ê°€ CORS (ìš´ì˜ì‹œ)
EXTRA_ALLOWED_ORIGINS=https://your-domain.com,https://app.your-domain.com

# ë³´ì•ˆ (ìš´ì˜ì‹œ)
ADMIN_API_KEY=super-secret-admin-key
USE_REDIS_FOR_STICKY=false
USE_REDIS_FOR_RATE_LIMIT=false
```

### **ìš´ì˜ í™˜ê²½ (ì¶”ê°€ ì„¤ì •)**
```bash
DEBUG=false
ADMIN_API_KEY=production-admin-secret-key
REDIS_URL=redis://localhost:6379/0
USE_REDIS_FOR_STICKY=true
USE_REDIS_FOR_RATE_LIMIT=true
```

---

## ğŸ§ª **í…ŒìŠ¤íŠ¸ ì»¤ë§¨ë“œ ëª¨ìŒ**

### **ê¸°ë³¸ ìƒë‹´ API**
```bash
curl -X POST http://127.0.0.1:8000/api/chat/completion \
  -H "Content-Type: application/json" \
  -H "x-user-tier: free" \
  -d '{"message":"ìš”ì¦˜ ë¶ˆì•ˆí•´ì„œ ìƒë‹´ì´ í•„ìš”í•´ìš”"}'
```

### **ì—”ì§„ ê°•ì œ ì„ íƒ**
```bash
# Engine A ê°•ì œ
curl -X POST http://127.0.0.1:8000/api/chat/completion \
  -H "Content-Type: application/json" \
  -H "x-user-tier: free" \
  -H "x-free-engine: engine_a" \
  -d '{"message":"Llama-3 ì—”ì§„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸"}'

# Engine B ê°•ì œ
curl -X POST http://127.0.0.1:8000/api/chat/completion \
  -H "Content-Type: application/json" \
  -H "x-user-tier: free" \
  -H "x-free-engine: engine_b" \
  -d '{"message":"Qwen2.5 ì—”ì§„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸"}'
```

### **Sticky ì„¸ì…˜ í…ŒìŠ¤íŠ¸**
```bash
# ì‚¬ìš©ì 123 - ì²« ë²ˆì§¸ í˜¸ì¶œ
curl -X POST http://127.0.0.1:8000/api/chat/completion \
  -H "Content-Type: application/json" \
  -H "x-user-tier: free" \
  -H "x-user-id: user123" \
  -d '{"message":"Sticky í…ŒìŠ¤íŠ¸ 1íšŒì°¨"}'

# ì‚¬ìš©ì 123 - ë‘ ë²ˆì§¸ í˜¸ì¶œ (ê°™ì€ ì—”ì§„ì´ì–´ì•¼ ì •ìƒ)
curl -X POST http://127.0.0.1:8000/api/chat/completion \
  -H "Content-Type: application/json" \
  -H "x-user-tier: free" \
  -H "x-user-id: user123" \
  -d '{"message":"Sticky í…ŒìŠ¤íŠ¸ 2íšŒì°¨"}'
```

### **í—¬ìŠ¤ì²´í¬ ëª¨ìŒ**
```bash
# ê¸°ë³¸ ì„œë²„ ìƒíƒœ
curl http://127.0.0.1:8000/health

# vLLM ì—…ìŠ¤íŠ¸ë¦¼ ìƒíƒœ (ê°œë°œí™˜ê²½)
curl http://127.0.0.1:8000/health/upstreams

# vLLM ì—…ìŠ¤íŠ¸ë¦¼ ìƒíƒœ (ìš´ì˜í™˜ê²½)
curl -H "x-admin-token: your-admin-key" \
     http://127.0.0.1:8000/health/upstreams
```

---

## ğŸš¨ **ë¬¸ì œí•´ê²° ê°€ì´ë“œ**

### **vLLM ì—”ì§„ ì—°ê²° ì‹¤íŒ¨**
```bash
# í¬íŠ¸ ì‚¬ìš© í™•ì¸
netstat -ano | findstr "8001\|8002"

# WSL2ì—ì„œ vLLM ì¬ì‹œì‘
pkill -f vllm
# ìœ„ì˜ ì—”ì§„ ì‹¤í–‰ ëª…ë ¹ì–´ ì¬ì‹¤í–‰
```

### **ë°±ì—”ë“œ ì„œë²„ ì˜¤ë¥˜**
```bash
# ë¡œê·¸ í™•ì¸
tail -f C:\Users\lco20\Desktop\EFT-AI-App\backend\logs\eft_ai_server.log

# í¬íŠ¸ 8000 ì‚¬ìš© í™•ì¸
netstat -ano | findstr :8000
```

### **CORS ì˜¤ë¥˜ (í”„ë¡ íŠ¸ì—”ë“œ)**
- `EXTRA_ALLOWED_ORIGINS` í™˜ê²½ë³€ìˆ˜ì— í”„ë¡ íŠ¸ì—”ë“œ ë„ë©”ì¸ ì¶”ê°€
- ê°œë°œ: `http://localhost:5173,http://127.0.0.1:5173`

---

## âš¡ **ì„±ëŠ¥ íŠœë‹**

### **vLLM ìµœì í™”**
```bash
# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¡°ì •
--gpu-memory-utilization 0.8  # ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ë‚®ì¶”ê¸°

# ëª¨ë¸ ê¸¸ì´ ì¡°ì •  
--max-model-len 2048  # ë©”ëª¨ë¦¬ ì ˆì•½ì‹œ ë‚®ì¶”ê¸°

# ë°°ì¹˜ í¬ê¸° ì¡°ì •
--max-num-batched-tokens 4096
```

### **ë°±ì—”ë“œ ìµœì í™”**
```bash
# ë©€í‹°ì›Œì»¤ ì‹¤í–‰ (ìš´ì˜í™˜ê²½)
uvicorn main:app --workers 4 --host 0.0.0.0 --port 8000

# í”„ë¡œì„¸ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ ì œí•œ
--limit-memory 2GB --limit-cpu 2
```

---

## ğŸ”’ **ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸**

- [ ] `ADMIN_API_KEY` ì„¤ì • (ìš´ì˜í™˜ê²½)
- [ ] `DEBUG=false` ì„¤ì • (ìš´ì˜í™˜ê²½)  
- [ ] HTTPS ì¸ì¦ì„œ ì„¤ì •
- [ ] ë°©í™”ë²½ ê·œì¹™: 8001/8002 í¬íŠ¸ëŠ” ë‚´ë¶€ë§ë§Œ
- [ ] ë¡œê·¸ íŒŒì¼ ê¶Œí•œ 600 ì„¤ì •
- [ ] `.env` íŒŒì¼ `.gitignore` í™•ì¸

---

## ğŸ“Š **ëª¨ë‹ˆí„°ë§ ì§€í‘œ**

### **í•µì‹¬ ë©”íŠ¸ë¦­**
- ì‘ë‹µ ì‹œê°„: `processing_time` < 3ì´ˆ
- ì—ëŸ¬ìœ¨: < 1%
- ê°€ìš©ì„±: > 99.9%
- vLLM ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : < 90%

### **ì•Œë¦¼ ì¡°ê±´**
- ì—…ìŠ¤íŠ¸ë¦¼ `status != "healthy"`
- ì—°ì† 5íšŒ API ì‹¤íŒ¨
- ì‘ë‹µ ì‹œê°„ > 10ì´ˆ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  > 95%

---

**âœ… AC: ì‹ ê·œ ê¸°ê¸°ë„ ì´ ë¬¸ì„œë§Œ ë³´ê³  1íšŒì— ê¸°ë™ ì„±ê³µ**